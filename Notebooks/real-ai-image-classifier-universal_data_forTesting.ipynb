{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6311868,"sourceType":"datasetVersion","datasetId":3428745},{"sourceId":9314036,"sourceType":"datasetVersion","datasetId":5641008},{"sourceId":9842648,"sourceType":"datasetVersion","datasetId":6038393},{"sourceId":196291,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":167375,"modelId":189693}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nprint(\"TensorFlow Version:\", tf.__version__)\nprint(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n\nfrom tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:00:29.075993Z","iopub.execute_input":"2024-12-12T14:00:29.076661Z","iopub.status.idle":"2024-12-12T14:00:39.951052Z","shell.execute_reply.started":"2024-12-12T14:00:29.076606Z","shell.execute_reply":"2024-12-12T14:00:39.950083Z"}},"outputs":[{"name":"stdout","text":"TensorFlow Version: 2.16.1\nGPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 7925044512530487199\nxla_global_id: -1\n, name: \"/device:GPU:0\"\ndevice_type: \"GPU\"\nmemory_limit: 14619377664\nlocality {\n  bus_id: 1\n  links {\n    link {\n      device_id: 1\n      type: \"StreamExecutor\"\n      strength: 1\n    }\n  }\n}\nincarnation: 17312499104362444936\nphysical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\nxla_global_id: 416903419\n, name: \"/device:GPU:1\"\ndevice_type: \"GPU\"\nmemory_limit: 14619377664\nlocality {\n  bus_id: 1\n  links {\n    link {\n      type: \"StreamExecutor\"\n      strength: 1\n    }\n  }\n}\nincarnation: 2554638220353052081\nphysical_device_desc: \"device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\"\nxla_global_id: 2144165316\n]\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Get directory path\n\nimport os\n\n# Base directory path\nbase_path = '/kaggle/input/real-ai-art/Real_AI_SD_LD_Dataset/train'\n\n# Get all subdirectories in the base path\nall_directories = [os.path.join(base_path, folder) for folder in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, folder))]\nreals = []\nfakes = []\n# Separate directories into AI and Real based on the naming convention\nai_directories = [dir_path for dir_path in all_directories if os.path.basename(dir_path).startswith('AI_')]\nreal_directories = [dir_path for dir_path in all_directories if not os.path.basename(dir_path).startswith('AI_')]\n\n# Print the results\nprint(\"AI Directories:\")\nfor ai_dir in ai_directories:\n    fakes.append(ai_dir)\n\nprint(\"\\nReal Directories:\")\nfor real_dir in real_directories:\n    reals.append(real_dir)\n\n# Optional: Print the counts\nprint(f\"\\nTotal AI Directories: {len(ai_directories)}\")\nprint(f\"Total Real Directories: {len(real_directories)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:00:39.952554Z","iopub.execute_input":"2024-12-12T14:00:39.953088Z","iopub.status.idle":"2024-12-12T14:00:39.976078Z","shell.execute_reply.started":"2024-12-12T14:00:39.953057Z","shell.execute_reply":"2024-12-12T14:00:39.975165Z"}},"outputs":[{"name":"stdout","text":"AI Directories:\n\nReal Directories:\n\nTotal AI Directories: 20\nTotal Real Directories: 10\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Override output directories\n\nimport os\nimport shutil\n\n# Path to the folder you want to override\nfolder_path_fake_train = '/kaggle/working/Mixed_dataset/train/Fake'\nfolder_path_real_train = '/kaggle/working/Mixed_dataset/train/Real'\nfolder_path_fake_val = '/kaggle/working/Mixed_dataset/val/Fake'\nfolder_path_real_val = '/kaggle/working/Mixed_dataset/val/Real'\n\n# Remove the existing folder and its contents (if it exists)\ndef make_folder(folder_path):\n    if os.path.exists(folder_path):\n        shutil.rmtree(folder_path)\n        os.makedirs(folder_path)\n\n    else:\n        # Recreate the folder\n        os.makedirs(folder_path)\n\nmake_folder(folder_path_fake_train)\nmake_folder(folder_path_real_train)\nmake_folder(folder_path_fake_val)\nmake_folder(folder_path_real_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:00:39.976975Z","iopub.execute_input":"2024-12-12T14:00:39.977201Z","iopub.status.idle":"2024-12-12T14:00:39.983423Z","shell.execute_reply.started":"2024-12-12T14:00:39.977178Z","shell.execute_reply":"2024-12-12T14:00:39.982573Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Create dataset\n\nimport os\nimport shutil\nimport random\nfrom glob import glob\n\n# List of source directories for real and fake images\nsource_real_dirs = [\n    '/kaggle/input/real-fake-image-full-dataset/0_real',\n    '/kaggle/input/real-and-fake-images-dataset-for-image-forensics/Data Set 1/Data Set 1/train/real',\n    '/kaggle/input/real-and-fake-images-dataset-for-image-forensics/Data Set 2/Data Set 2/train/real',\n    '/kaggle/input/real-and-fake-images-dataset-for-image-forensics/Data Set 3/Data Set 3/train/real',\n    '/kaggle/input/real-and-fake-images-dataset-for-image-forensics/Data Set 4/Data Set 4/train/real'\n]\n\nfor real in reals:\n    source_real_dirs.append(real)\n\nsource_fake_dirs = [\n    '/kaggle/input/real-fake-image-full-dataset/1_fake',\n    '/kaggle/input/real-and-fake-images-dataset-for-image-forensics/Data Set 1/Data Set 1/train/fake',\n    '/kaggle/input/real-and-fake-images-dataset-for-image-forensics/Data Set 2/Data Set 2/train/fake',\n    '/kaggle/input/real-and-fake-images-dataset-for-image-forensics/Data Set 3/Data Set 3/train/fake',\n    '/kaggle/input/real-and-fake-images-dataset-for-image-forensics/Data Set 4/Data Set 4/train/fake'\n]\n\nfor fake in fakes:\n    source_fake_dirs.append(fake)\n\n# Paths to the target directories\ntarget_real = '/kaggle/working/Mixed_dataset/train/Real'\ntarget_fake = '/kaggle/working/Mixed_dataset/train/Fake'\n\nall_selected = []\n\n# Function to copy random images from source directories to the target directory\ndef copy_random_images(source_dirs, target_dir, count):\n    for source_dir in source_dirs:\n        all_images = []\n        # Get all image file paths from the source directory\n        images = glob(os.path.join(source_dir, '*'))\n        all_images.extend(images)\n    \n        # Randomly select `count` images (or fewer if not enough images available)\n        selected_images = random.sample(all_images, min(count, len(all_images)))\n        all_selected.extend(selected_images)\n\n        # Copy the selected images to the target directory\n        for img_path in selected_images:\n            shutil.copy(img_path, target_dir)\n\n# Copy random images to the target directories\ncopy_random_images(source_real_dirs, target_real, 500)\ncopy_random_images(source_fake_dirs, target_fake, 500)\n\n# Function to shuffle images in the target directory\ndef shuffle_images(directory):\n    # Get all image paths in the directory\n    images = glob(os.path.join(directory, '*'))\n    \n    # Shuffle the images\n    random.shuffle(images)\n    \n# Shuffle images in both target directories\nshuffle_images(target_real)\nshuffle_images(target_fake)\n\nprint(f\"Images have been copied and shuffled in:\\n- {target_real}\\n- {target_fake}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:00:39.985795Z","iopub.execute_input":"2024-12-12T14:00:39.986332Z","iopub.status.idle":"2024-12-12T14:04:08.932026Z","shell.execute_reply.started":"2024-12-12T14:00:39.986302Z","shell.execute_reply":"2024-12-12T14:04:08.931149Z"}},"outputs":[{"name":"stdout","text":"Images have been copied and shuffled in:\n- /kaggle/working/Mixed_dataset/train/Real\n- /kaggle/working/Mixed_dataset/train/Fake\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"target_real = '/kaggle/working/Mixed_dataset/val/Real'\ntarget_fake = '/kaggle/working/Mixed_dataset/val/Fake'\n\n\n# Function to copy random images from source directories to the target directory for validation\ndef copy_random_images_val(source_dirs, target_dir, count):\n    for source_dir in source_dirs:\n        image_count=count\n        all_images = []\n        # Get all image file paths from the source directory\n        images = glob(os.path.join(source_dir, '*'))\n        all_images.extend(images)\n    \n        # Randomly select `count` images (or fewer if not enough images available)\n        while image_count != 0:\n            selected_image = random.sample(all_images, 1)\n            if selected_image[0] not in all_selected:\n                shutil.copy(selected_image[0], target_dir)\n                image_count=image_count-1\n\ncopy_random_images_val(source_real_dirs, target_real, 10)\ncopy_random_images_val(source_fake_dirs, target_fake, 5)\n\nprint(f\"Images have been copied in:\\n- {target_real}\\n- {target_fake}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:04:08.933241Z","iopub.execute_input":"2024-12-12T14:04:08.933610Z","iopub.status.idle":"2024-12-12T14:04:12.492209Z","shell.execute_reply.started":"2024-12-12T14:04:08.933570Z","shell.execute_reply":"2024-12-12T14:04:12.491365Z"}},"outputs":[{"name":"stdout","text":"Images have been copied in:\n- /kaggle/working/Mixed_dataset/val/Real\n- /kaggle/working/Mixed_dataset/val/Fake\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import PIL.Image\nimport cv2\nimport numpy as np\nimport random\nimport concurrent.futures\n\ndef img_to_patches(input_path:str) -> tuple:\n    \"\"\"\n    Returns 32x32 patches of a resized 256x256 images,\n    it returns 64x64 patches on grayscale and 64x64 patches\n    on the RGB color scale\n    --------------------------------------------------------\n    ## parameters:\n    - input_path: Accepts input path of the image\n    \"\"\"\n    img = PIL.Image.open(fp=input_path)\n    if(input_path[-3:]!='jpg' or input_path[-4:]!='jpeg'):\n        img = img.convert('RGB')\n    if(img.size!=(256,256)):\n        img = img.resize(size=(256,256))\n    patch_size = 32\n    grayscale_imgs = []\n    imgs = []\n    for i in range(0,img.height,patch_size):\n        for j in range(0, img.width, patch_size):\n            box = (j,i,j+patch_size,i+patch_size)\n            img_color = np.asarray(img.crop(box))\n            grayscale_image = cv2.cvtColor(src=img_color, code=cv2.COLOR_RGB2GRAY)\n            grayscale_imgs.append(grayscale_image.astype(dtype=np.int32))\n            imgs.append(img_color)\n    return grayscale_imgs,imgs\n\n\n\ndef get_l1(v,x,y):\n    l1=0\n    # 1 to m, 1 to m-1\n    for i in range(0,y-1):\n        for j  in range(0,x):\n            l1+=abs(v[j][i]-v[j][i+1])\n    return l1\n\ndef get_l2(v,x,y):\n    l2=0\n    # 1 to m-1, 1 to m\n    for i in range(0,y):\n        for j  in range(0,x-1):\n            l2+=abs(v[j][i]-v[j+1][i])\n    return l2\n\ndef get_l3l4(v,x,y):\n    l3=l4=0\n    # 1 to m-1, 1 to m-1\n    for i in range(0,y-1):\n        for j  in range(0,x-1):\n            l3+=abs(v[j][i]-v[j+1][i+1])\n            l4+=abs(v[j+1][i]-v[j][i+1])\n\n    return l3+l4\n\ndef get_pixel_var_degree_for_patch(patch:np.array)->int:\n    \"\"\"\n    gives pixel variation for a given patch\n    ---------------------------------------\n    ## parameters:\n    - patch: accepts a numpy array format of the patch of an image\n    \"\"\"\n    x,y = patch.shape\n    l1=l2=l3l4=0\n    \n    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n        future_l1 = executor.submit(get_l1,patch,x,y)\n        future_l2 = executor.submit(get_l2,patch,x,y)\n        future_l3l4 = executor.submit(get_l3l4,patch,x,y)\n\n        l1 = future_l1.result()\n        l2 = future_l2.result()\n        l3l4 = future_l3l4.result()\n\n    return  l1+l2+l3l4\n\n\ndef extract_rich_and_poor_textures(variance_values:list, patches:list):\n    \"\"\"\n    returns a list of rich texture and poor texture patches respectively\n    --------------------------------------------------------------------\n    ## parameters:\n    - variance_values: list of values that are pixel variances of each patch\n    - color_patches: coloured patches of the target image\n    \"\"\"\n    threshold = np.mean(variance_values)\n    rich_texture_patches = []\n    poor_texture_patches = []\n    for i,j in enumerate(variance_values):\n        if j >= threshold:\n            rich_texture_patches.append(patches[i])\n        else:\n            poor_texture_patches.append(patches[i])\n    \n    return rich_texture_patches, poor_texture_patches\n\n\n\ndef get_complete_image(patches:list, coloured=True):\n    \"\"\"\n    Develops complete 265x256 image from rich and poor texture patches\n    ------------------------------------------------------------------\n    ## parameters:\n    - patches: Takes a list of rich or poor texture patches\n    \"\"\"\n    random.shuffle(patches)\n    p_len = len(patches)\n    while len(patches)<64:\n        patches.append(patches[random.randint(0, p_len-1)])\n    \n    if(coloured==True):\n        grid = np.asarray(patches).reshape((8,8,32,32,3))\n    else:\n        grid = np.asarray(patches).reshape((8,8,32,32))\n\n\n    # joins columns to only leave rows\n    rows = [np.concatenate(grid[i,:], axis=1) for i in range(8)]\n\n    # joins the rows to create the final image\n    img = np.concatenate(rows,axis=0)\n\n    return img\n    \n\n\ndef smash_n_reconstruct(input_path:str, coloured=True):\n    \"\"\"\n    Performs the SmashnReconstruct part of preprocesing\n    reference: [link](https://arxiv.org/abs/2311.12397)\n\n    return rich_texture,poor_texture\n    \n    ----------------------------------------------------\n    ## parameters:\n    - input_path: Accepts input path of the image\n    \"\"\"\n    gray_scale_patches, color_patches = img_to_patches(input_path=input_path)\n    pixel_var_degree = []\n    for patch in gray_scale_patches:\n        pixel_var_degree.append(get_pixel_var_degree_for_patch(patch))\n    \n    # r_patch = list of rich texture patches, p_patch = list of poor texture patches\n    if(coloured):\n        r_patch,p_patch = extract_rich_and_poor_textures(variance_values=pixel_var_degree,patches=color_patches)\n    else:\n        r_patch,p_patch = extract_rich_and_poor_textures(variance_values=pixel_var_degree,patches=gray_scale_patches)\n    rich_texture,poor_texture = None,None\n\n    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n        rich_texture_future = executor.submit(get_complete_image,r_patch,coloured)\n        poor_texture_future = executor.submit(get_complete_image,p_patch,coloured)\n\n        rich_texture = rich_texture_future.result()\n        poor_texture = poor_texture_future.result()\n\n    return rich_texture, poor_texture\n\nif __name__==\"main\":\n    smash_n_reconstruct(input_path=\"placeholder\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-12-12T14:04:12.493446Z","iopub.execute_input":"2024-12-12T14:04:12.493776Z","iopub.status.idle":"2024-12-12T14:04:12.687322Z","shell.execute_reply.started":"2024-12-12T14:04:12.493749Z","shell.execute_reply":"2024-12-12T14:04:12.686598Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import numpy as np\nimport cv2\nfrom scipy.ndimage import rotate\n\ndef apply_filter_a(src:np.ndarray):\n    src_copy = np.copy(src)\n    f1 = np.array([[[ 0,  0,  0,  0,  0],\n        [ 0,  1,  0,  0,  0],\n        [ 0,  0, -1,  0,  0],\n        [ 0,  0,  0,  0,  0],\n        [ 0,  0,  0,  0,  0]],\n\n       [[ 0,  0,  0,  0,  0],\n        [ 0,  0,  1,  0,  0],\n        [ 0,  0, -1,  0,  0],\n        [ 0,  0,  0,  0,  0],\n        [ 0,  0,  0,  0,  0]],\n\n       [[ 0,  0,  0,  0,  0],\n        [ 0,  0,  0,  1,  0],\n        [ 0,  0, -1,  0,  0],\n        [ 0,  0,  0,  0,  0],\n        [ 0,  0,  0,  0,  0]],\n\n       [[ 0,  0,  0,  0,  0],\n        [ 0,  0,  0,  0,  0],\n        [ 0,  0, -1,  1,  0],\n        [ 0,  0,  0,  0,  0],\n        [ 0,  0,  0,  0,  0]],\n\n       [[ 0,  0,  0,  0,  0],\n        [ 0,  0,  0,  0,  0],\n        [ 0,  0, -1,  0,  0],\n        [ 0,  0,  0,  1,  0],\n        [ 0,  0,  0,  0,  0]],\n\n       [[ 0,  0,  0,  0,  0],\n        [ 0,  0,  0,  0,  0],\n        [ 0,  0, -1,  0,  0],\n        [ 0,  0,  1,  0,  0],\n        [ 0,  0,  0,  0,  0]],\n\n       [[ 0,  0,  0,  0,  0],\n        [ 0,  0,  0,  0,  0],\n        [ 0,  0, -1,  0,  0],\n        [ 0,  1,  0,  0,  0],\n        [ 0,  0,  0,  0,  0]],\n\n       [[ 0,  0,  0,  0,  0],\n        [ 0,  0,  0,  0,  0],\n        [ 0,  1, -1,  0,  0],\n        [ 0,  0,  0,  0,  0],\n        [ 0,  0,  0,  0,  0]]])\n    \n    img = cv2.filter2D(src=src_copy, kernel=f1[0], ddepth=-1)\n    for filter in f1[1:]:\n        img = cv2.add(img,cv2.filter2D(src=src_copy, kernel=filter, ddepth=-1))\n\n    return img//8\n\ndef apply_filter_b(src:np.ndarray):\n    src_copy = np.copy(src)\n    f2 = np.array([[[ 0,  0,  0,  0,  0],\n                    [ 0,  2,  1,  0,  0],\n                    [ 0,  1, -3,  0,  0],\n                    [ 0,  0,  0,  1,  0],\n                    [ 0,  0,  0,  0,  0]],\n\n                    [[ 0,  0, -1,  0,  0],\n                    [ 0,  0,  3,  0,  0],\n                    [ 0,  0, -3,  0,  0],\n                    [ 0,  0,  1,  0,  0],\n                    [ 0,  0,  0,  0,  0]],\n\n                    [[ 0,  0,  0,  0,  0],\n                    [ 0,  0,  1,  2,  0],\n                    [ 0,  0, -3,  1,  0],\n                    [ 0,  1,  0,  0,  0],\n                    [ 0,  0,  0,  0,  0]],\n\n                    [[ 0,  0,  0,  0,  0],\n                    [ 0,  0,  0,  0,  0],\n                    [ 0,  1, -3,  3, -1],\n                    [ 0,  0,  0,  0,  0],\n                    [ 0,  0,  0,  0,  0]],\n\n                    [[ 0,  0,  0,  0,  0],\n                    [ 0,  1,  0,  0,  0],\n                    [ 0,  0, -3,  1,  0],\n                    [ 0,  0,  1,  2,  0],\n                    [ 0,  0,  0,  0,  0]],\n\n                    [[ 0,  0,  0,  0,  0],\n                    [ 0,  0,  1,  0,  0],\n                    [ 0,  0, -3,  0,  0],\n                    [ 0,  0,  3,  0,  0],\n                    [ 0,  0, -1,  0,  0]],\n\n                    [[ 0,  0,  0,  0,  0],\n                    [ 0,  0,  0,  1,  0],\n                    [ 0,  1, -3,  0,  0],\n                    [ 0,  2,  1,  0,  0],\n                    [ 0,  0,  0,  0,  0]],\n\n                    [[ 0,  0,  0,  0,  0],\n                    [ 0,  0,  0,  0,  0],\n                    [-1,  3, -3,  1,  0],\n                    [ 0,  0,  0,  0,  0],\n                    [ 0,  0,  0,  0,  0]]])\n\n    img = cv2.filter2D(src=src_copy, kernel=f2[0], ddepth=-1)\n    for filter in f2[1:]:\n        img = cv2.add(img,cv2.filter2D(src=src_copy, kernel=filter, ddepth=-1))\n\n    return img//8\n\n\n\ndef apply_filter_c(src:np.ndarray):\n    src_copy=np.copy(src)\n    f3 = np.array([[[ 0,  0,  0,  0,  0],\n                    [ 0,  0,  1,  0,  0],\n                    [ 0,  0, -2,  0,  0],\n                    [ 0,  0,  1,  0,  0],\n                    [ 0,  0,  0,  0,  0]],\n\n                    [[ 0,  0,  0,  0,  0],\n                    [ 0,  0,  0,  0,  0],\n                    [ 0,  1, -2,  1,  0],\n                    [ 0,  0,  0,  0,  0],\n                    [ 0,  0,  0,  0,  0]],\n\n                    [[ 0,  0,  0,  0,  0],\n                    [ 0,  1,  0,  0,  0],\n                    [ 0,  0, -2,  0,  0],\n                    [ 0,  0,  0,  1,  0],\n                    [ 0,  0,  0,  0,  0]],\n\n                    [[ 0,  0,  0,  0,  0],\n                    [ 0,  0,  0,  1,  0],\n                    [ 0,  0, -2,  0,  0],\n                    [ 0,  1,  0,  0,  0],\n                    [ 0,  0,  0,  0,  0]]])\n    \n    img = cv2.filter2D(src=src_copy, kernel=f3[0], ddepth=-1)\n    for filter in f3[1:]:\n        img = cv2.add(img,cv2.filter2D(src=src_copy, kernel=filter, ddepth=-1))\n\n    return img//4\n\n\ndef apply_filter_d(src:np.ndarray):\n    src_copy=np.copy(src)\n    f4 = np.array([[[ 0,  0,  0,  0,  0],\n                    [ 0, -1,  2, -1,  0],\n                    [ 0,  2, -4,  2,  0],\n                    [ 0,  0,  0,  0,  0],\n                    [ 0,  0,  0,  0,  0]],\n\n                    [[ 0,  0,  0,  0,  0],\n                    [ 0, -1,  2,  0,  0],\n                    [ 0,  2, -4,  0,  0],\n                    [ 0, -1,  2,  0,  0],\n                    [ 0,  0,  0,  0,  0]],\n\n                    [[ 0,  0,  0,  0,  0],\n                    [ 0,  0,  0,  0,  0],\n                    [ 0,  2, -4,  2,  0],\n                    [ 0, -1,  2, -1,  0],\n                    [ 0,  0,  0,  0,  0]],\n\n                    [[ 0,  0,  0,  0,  0],\n                    [ 0,  0,  2, -1,  0],\n                    [ 0,  0, -4,  2,  0],\n                    [ 0,  0,  2, -1,  0],\n                    [ 0,  0,  0,  0,  0]]])\n\n    img = cv2.filter2D(src=src_copy, kernel=f4[0], ddepth=-1)\n    for filter in f4[1:]:\n        img = cv2.add(img,cv2.filter2D(src=src_copy, kernel=filter, ddepth=-1))\n\n    return img//4\n\ndef apply_filter_e(src:np.ndarray):\n    src_copy=np.copy(src)\n    f5 = np.array([[[  1,   2,  -2,   2,   1],\n                    [  2,  -6,   8,  -6,   2],\n                    [ -2,   8, -12,   8,  -2],\n                    [  0,   0,   0,   0,   0],\n                    [  0,   0,   0,   0,   0]],\n\n                [[  1,   2,  -2,   0,   0],\n                    [  2,  -6,   8,   0,   0],\n                    [ -2,   8, -12,   0,   0],\n                    [  2,  -6,   8,   0,   0],\n                    [  1,   2,  -2,   0,   0]],\n\n                [[  0,   0,   0,   0,   0],\n                    [  0,   0,   0,   0,   0],\n                    [ -2,   8, -12,   8,  -2],\n                    [  2,  -6,   8,  -6,   2],\n                    [  1,   2,  -2,   2,   1]],\n\n                [[  0,   0,  -2,   2,   1],\n                    [  0,   0,   8,  -6,   2],\n                    [  0,   0, -12,   8,  -2],\n                    [  0,   0,   8,  -6,   2],\n                    [  0,   0,  -2,   2,   1]]])\n    \n    img = cv2.filter2D(src=src_copy, kernel=f5[0], ddepth=-1)\n    for filter in f5[1:]:\n        img=cv2.add(img,cv2.filter2D(src=src_copy, kernel=filter, ddepth=-1))\n\n    return img//4\n\ndef apply_filter_f(src:np.ndarray):\n    src_copy=np.copy(src)\n    f5 = np.asarray([[ 0,  0,  0,  0,  0],\n                    [ 0,  -1,  2, -1,  0],\n                    [ 0,  2,  -4,  2,  0],\n                    [ 0,  -1,  2, -1,  0],\n                    [ 0,  0,  0,  0,  0]])\n    \n    img = cv2.filter2D(src=src_copy, kernel=f5, ddepth=-1)\n    return img\n\n\ndef apply_filter_g(src:np.ndarray):\n    src_copy=np.copy(src)\n    f5 = np.asarray([[ -1,   2,  -2,   2,  -1],\n                    [  2,  -6,   8,  -6,   2],\n                    [ -2,   8, -12,   8,  -2],\n                    [  2,  -6,   8,  -6,   2],\n                    [ -1,   2,  -2,   2,  -1]])\n    \n    img = cv2.filter2D(src=src_copy, kernel=f5, ddepth=-1)\n    return img\n\ndef apply_all_filters(src:np.ndarray):\n    src_copy = np.copy(src)\n    img = np.array(cv2.cvtColor((apply_filter_a(src_copy) + apply_filter_b(src_copy) + apply_filter_c(src_copy) + \\\n            apply_filter_d(src_copy) + apply_filter_e(src_copy) + apply_filter_f(src_copy) + apply_filter_g(src_copy)), cv2.COLOR_RGB2GRAY)//7)\n    img_thresh = np.median(img)+2\n    return cv2.threshold(img,img_thresh,255,cv2.THRESH_BINARY)[1]","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-12-12T14:04:12.688557Z","iopub.execute_input":"2024-12-12T14:04:12.688917Z","iopub.status.idle":"2024-12-12T14:04:12.735831Z","shell.execute_reply.started":"2024-12-12T14:04:12.688881Z","shell.execute_reply":"2024-12-12T14:04:12.734991Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras import layers,Model\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:04:12.736923Z","iopub.execute_input":"2024-12-12T14:04:12.737752Z","iopub.status.idle":"2024-12-12T14:04:12.742313Z","shell.execute_reply.started":"2024-12-12T14:04:12.737722Z","shell.execute_reply":"2024-12-12T14:04:12.741333Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from tensorflow.keras.layers import Layer\nfrom tensorflow.keras.saving import register_keras_serializable\n\n@tf.function\ndef hard_tanh(x):\n    return tf.maximum(tf.minimum(x, 1), -1)\n    \n@register_keras_serializable(package=\"Custom\", name=\"featureExtractionLayer\")\nclass featureExtractionLayer(layers.Layer):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.conv = layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu')\n        self.bn = layers.BatchNormalization()\n        self.activation = layers.Lambda(hard_tanh)\n        \n    \n    def call(self, input):\n        x = self.conv(input)\n        x = self.bn(x)\n        x = self.activation(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:04:12.743466Z","iopub.execute_input":"2024-12-12T14:04:12.743777Z","iopub.status.idle":"2024-12-12T14:04:12.814306Z","shell.execute_reply.started":"2024-12-12T14:04:12.743750Z","shell.execute_reply":"2024-12-12T14:04:12.813319Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"input1 = layers.Input(shape=(256,256,1),name=\"rich_texture\")\ninput2 = layers.Input(shape=(256,256,1),name=\"poor_texture\")\n\nl1 = featureExtractionLayer(name=\"feature_extraction_layer_rich_texture\")(input1)\nl2 = featureExtractionLayer(name=\"feature_extraction_layer_poor_texture\")(input2)\n\ncontrast = layers.subtract((l1,l2))\n\nx = layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu')(contrast)\nx = layers.BatchNormalization()(x)\nfor i in range(3):\n    x = layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu')(x)\n    x = layers.BatchNormalization()(x)\nx = layers.BatchNormalization()(x)\n\nfor i in range(4):\n    x = layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu')(x)\n    x = layers.BatchNormalization()(x)\nx = layers.AveragePooling2D(3,3)(x)\n\nfor i in range(2):\n    x = layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu')(x)\n    x = layers.BatchNormalization()(x)\nx = layers.AveragePooling2D(3,3)(x)\n\nfor i in range(2):\n    x = layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu')(x)\n    x = layers.BatchNormalization()(x)\nx = layers.GlobalAveragePooling2D()(x)\n\nx = layers.Flatten()(x)\nx = layers.Dense(1,activation='sigmoid')(x)\n\nmodel = Model(inputs=(input1,input2), outputs=x, name=\"rich_texture_poor_texture_contrast\")\nmodel.compile(\n                optimizer='adam',\n                loss='BinaryCrossentropy',\n                metrics=['binary_accuracy']\n            )\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:04:12.818748Z","iopub.execute_input":"2024-12-12T14:04:12.819536Z","iopub.status.idle":"2024-12-12T14:04:13.593265Z","shell.execute_reply.started":"2024-12-12T14:04:12.819480Z","shell.execute_reply":"2024-12-12T14:04:13.592417Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"rich_texture_poor_texture_contrast\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"rich_texture_poor_texture_contrast\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ rich_texture        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ poor_texture        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ feature_extraction… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m254\u001b[0m,  │        \u001b[38;5;34m448\u001b[0m │ rich_texture[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mfeatureExtraction…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ feature_extraction… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m254\u001b[0m,  │        \u001b[38;5;34m448\u001b[0m │ poor_texture[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mfeatureExtraction…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ subtract (\u001b[38;5;33mSubtract\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m254\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ feature_extracti… │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │ feature_extracti… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m252\u001b[0m, \u001b[38;5;34m252\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ subtract[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m252\u001b[0m, \u001b[38;5;34m252\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m250\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ batch_normalizat… │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m250\u001b[0m, \u001b[38;5;34m250\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m248\u001b[0m, \u001b[38;5;34m248\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ batch_normalizat… │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m248\u001b[0m, \u001b[38;5;34m248\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m246\u001b[0m, \u001b[38;5;34m246\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ batch_normalizat… │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m246\u001b[0m, \u001b[38;5;34m246\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m246\u001b[0m, \u001b[38;5;34m246\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ batch_normalizat… │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m242\u001b[0m, \u001b[38;5;34m242\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ batch_normalizat… │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m242\u001b[0m, \u001b[38;5;34m242\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ batch_normalizat… │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m238\u001b[0m, \u001b[38;5;34m238\u001b[0m,  │      \u001b[38;5;34m9,248\u001b[0m │ batch_normalizat… │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m238\u001b[0m, \u001b[38;5;34m238\u001b[0m,  │        \u001b[38;5;34m128\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ average_pooling2d   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m79\u001b[0m, \u001b[38;5;34m79\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m77\u001b[0m, \u001b[38;5;34m77\u001b[0m,    │      \u001b[38;5;34m9,248\u001b[0m │ average_pooling2… │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m77\u001b[0m, \u001b[38;5;34m77\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m,    │      \u001b[38;5;34m9,248\u001b[0m │ batch_normalizat… │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m, \u001b[38;5;34m75\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ average_pooling2d_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)  │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m,    │      \u001b[38;5;34m9,248\u001b[0m │ average_pooling2… │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m, \u001b[38;5;34m23\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m21\u001b[0m,    │      \u001b[38;5;34m9,248\u001b[0m │ batch_normalizat… │\n│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m21\u001b[0m,    │        \u001b[38;5;34m128\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ rich_texture        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ poor_texture        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ feature_extraction… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ rich_texture[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">featureExtraction…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ feature_extraction… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ poor_texture[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">featureExtraction…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ subtract (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ feature_extracti… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │ feature_extracti… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">252</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">252</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ subtract[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">252</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">252</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ batch_normalizat… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">248</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ batch_normalizat… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">248</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">248</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">246</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ batch_normalizat… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">246</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">246</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">246</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ batch_normalizat… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">242</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">242</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ batch_normalizat… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">242</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">242</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ batch_normalizat… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">238</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">238</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ batch_normalizat… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">238</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">238</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ average_pooling2d   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">79</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">79</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">77</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">77</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ average_pooling2… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">77</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">77</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ batch_normalizat… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ average_pooling2d_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)  │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ average_pooling2… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │ batch_normalizat… │\n│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m113,569\u001b[0m (443.63 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">113,569</span> (443.63 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m112,609\u001b[0m (439.88 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,609</span> (439.88 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n</pre>\n"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\nmodel = load_model(\n    '/kaggle/input/universal_ai_real_image_classifier/keras/default/1/model_checkpoint_all_purpose.keras',\n    custom_objects={'featureExtractionLayer': featureExtractionLayer}\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:06:16.633546Z","iopub.execute_input":"2024-12-12T14:06:16.633959Z","iopub.status.idle":"2024-12-12T14:06:17.248407Z","shell.execute_reply.started":"2024-12-12T14:06:16.633927Z","shell.execute_reply":"2024-12-12T14:06:17.247748Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'feature_extraction_layer_rich_texture', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/layer.py:361: UserWarning: `build()` was called on layer 'feature_extraction_layer_poor_texture', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"path_ai_train = '/kaggle/working/Mixed_dataset/train/Fake'\nai_imgs_train = [os.path.join(path_ai_train,img) for img in os.listdir(path_ai_train)]\nai_label_train = [1 for i in range(len(ai_imgs_train))]\npath_real_train = '/kaggle/working/Mixed_dataset/train/Real'\nreal_imgs_train = [os.path.join(path_real_train,img) for img in os.listdir(path_real_train)]\nreal_label_train = [0 for i in range(len(real_imgs_train))]\nprint(len(real_imgs_train),len(ai_imgs_train))\nX_train = ai_imgs_train + real_imgs_train\ny_train = ai_label_train + real_label_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:06:21.804836Z","iopub.execute_input":"2024-12-12T14:06:21.805166Z","iopub.status.idle":"2024-12-12T14:06:21.843825Z","shell.execute_reply.started":"2024-12-12T14:06:21.805136Z","shell.execute_reply":"2024-12-12T14:06:21.842993Z"}},"outputs":[{"name":"stdout","text":"7500 12500\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"path_ai_val = '/kaggle/working/Mixed_dataset/val/Fake'\nai_imgs_val = [os.path.join(path_ai_val,img) for img in os.listdir(path_ai_val)]\nai_label_val = [1 for i in range(len(ai_imgs_val))]\npath_real_val = '/kaggle/working/Mixed_dataset/val/Real'\nreal_imgs_val = [os.path.join(path_real_val,img) for img in os.listdir(path_real_val)]\nreal_label_val = [0 for i in range(len(real_imgs_val))]\nprint(len(real_imgs_val),len(ai_imgs_val))\nX_validate = ai_imgs_val + real_imgs_val\ny_validate = ai_label_val + real_label_val","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:06:25.200415Z","iopub.execute_input":"2024-12-12T14:06:25.201200Z","iopub.status.idle":"2024-12-12T14:06:25.208225Z","shell.execute_reply.started":"2024-12-12T14:06:25.201163Z","shell.execute_reply":"2024-12-12T14:06:25.207276Z"}},"outputs":[{"name":"stdout","text":"150 125\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"len(X_train),len(y_train),len(X_validate),len(y_validate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:06:28.198987Z","iopub.execute_input":"2024-12-12T14:06:28.199760Z","iopub.status.idle":"2024-12-12T14:06:28.205520Z","shell.execute_reply.started":"2024-12-12T14:06:28.199722Z","shell.execute_reply":"2024-12-12T14:06:28.204612Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(20000, 20000, 275, 275)"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"def preprocess(path, label):\n    # Convert path to string if it's a tensor\n    path = path.numpy().decode('utf-8') if tf.is_tensor(path) else path\n    \n    try:\n        # Perform preprocessing\n        rt, pt = smash_n_reconstruct(path)\n        \n        # Apply filters and ensure consistent shape\n        frt = tf.cast(tf.expand_dims(apply_all_filters(rt), axis=-1), dtype=tf.float64)\n        fpt = tf.cast(tf.expand_dims(apply_all_filters(pt), axis=-1), dtype=tf.float64)\n        \n        # Ensure shape\n        frt = tf.ensure_shape(frt, [256, 256, 1])\n        fpt = tf.ensure_shape(fpt, [256, 256, 1])\n        label = tf.ensure_shape(label, [])\n        \n        return frt, fpt, label\n        \n    except Exception as e:\n        print(f\"Error processing {path}: {e}\")\n        # Return dummy tensors to avoid breaking the pipeline\n        dummy = tf.zeros([256, 256, 1], dtype=tf.float32)\n        return dummy, dummy, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:06:30.993048Z","iopub.execute_input":"2024-12-12T14:06:30.993928Z","iopub.status.idle":"2024-12-12T14:06:31.000222Z","shell.execute_reply.started":"2024-12-12T14:06:30.993892Z","shell.execute_reply":"2024-12-12T14:06:30.999165Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"batch_size = 16\n\ndataset = (tf.data.Dataset.from_tensor_slices((X_train, y_train))\n           .shuffle(len(X_train))\n           .map(\n                lambda filepath, label: \n                tf.py_function(preprocess, [filepath, label], [tf.float64, tf.float64, tf.int32])\n            )\n           .map(\n                lambda rich_texture, poor_texture, label: (\n                    {\n                        'rich_texture': tf.ensure_shape(rich_texture, (256, 256, 1)),\n                        'poor_texture': tf.ensure_shape(poor_texture, (256, 256, 1))\n                    },\n                    tf.ensure_shape(label, [])\n                )\n            )\n           .batch(batch_size)\n           .prefetch(tf.data.AUTOTUNE)\n        )\n\nvalidation_set = (tf.data.Dataset.from_tensor_slices((X_validate, y_validate))\n                  .map(\n                       lambda filepath, label: \n                       tf.py_function(preprocess, [filepath, label], [tf.float64, tf.float64, tf.int32])\n                   )\n                  .map(\n                       lambda rich_texture, poor_texture, label: (\n                           {\n                               'rich_texture': tf.ensure_shape(rich_texture, (256, 256, 1)),\n                               'poor_texture': tf.ensure_shape(poor_texture, (256, 256, 1))\n                           },\n                           tf.ensure_shape(label, [])\n                       )\n                   )\n                  .batch(batch_size)\n                  .prefetch(tf.data.AUTOTUNE)\n              )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:06:34.159232Z","iopub.execute_input":"2024-12-12T14:06:34.159696Z","iopub.status.idle":"2024-12-12T14:06:34.355440Z","shell.execute_reply.started":"2024-12-12T14:06:34.159650Z","shell.execute_reply":"2024-12-12T14:06:34.354400Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"checkpoint_path = \"/kaggle/working/model_checkpoint_universal.keras\"\ncheckpoint_callback = ModelCheckpoint(filepath=checkpoint_path, \n                                      monitor='val_loss', \n                                      save_best_only=True,\n                                      verbose=1)\n\nearly_stopping_callback = EarlyStopping(monitor='val_loss', \n                                        patience=2,\n                                        verbose=1, \n                                        restore_best_weights=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:06:37.824170Z","iopub.execute_input":"2024-12-12T14:06:37.824497Z","iopub.status.idle":"2024-12-12T14:06:37.829211Z","shell.execute_reply.started":"2024-12-12T14:06:37.824467Z","shell.execute_reply":"2024-12-12T14:06:37.828356Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"history = model.fit(dataset,\n                    epochs=4,\n                    batch_size=128,\n                    validation_data=validation_set,\n                    callbacks=[checkpoint_callback, early_stopping_callback]\n                   )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:06:40.688279Z","iopub.execute_input":"2024-12-12T14:06:40.688843Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/4\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1734012413.825317      93 service.cc:145] XLA service 0x7b617000d180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1734012413.825375      93 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1734012413.825379      93 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n2024-12-12 14:07:23.005282: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng4{k11=1} for conv (f32[32,32,242,242]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,240,240]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n2024-12-12 14:07:23.132563: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.127369197s\nTrying algorithm eng4{k11=1} for conv (f32[32,32,242,242]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,240,240]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Plot training and validation loss\nplt.figure(figsize=(12, 6))\n\n# Plot loss\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Training Loss', marker='o')\nplt.plot(history.history['val_loss'], label='Validation Loss', marker='o')\nplt.title('Loss Over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid()\n\n# Plot accuracy\nplt.subplot(1, 2, 2)\nplt.plot(history.history['binary_accuracy'], label='Training Accuracy', marker='o')\nplt.plot(history.history['val_binary_accuracy'], label='Validation Accuracy', marker='o')\nplt.title('Accuracy Over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:04:14.269935Z","iopub.status.idle":"2024-12-12T14:04:14.270446Z","shell.execute_reply.started":"2024-12-12T14:04:14.270177Z","shell.execute_reply":"2024-12-12T14:04:14.270205Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('./classifier_universal.keras')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:04:14.271455Z","iopub.status.idle":"2024-12-12T14:04:14.271908Z","shell.execute_reply.started":"2024-12-12T14:04:14.271682Z","shell.execute_reply":"2024-12-12T14:04:14.271706Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"def preprocess_image(path):\n    # Convert path to string if it's a tensor\n    path = path.numpy().decode('utf-8') if tf.is_tensor(path) else path\n    \n    try:\n        # Perform preprocessing\n        rt, pt = smash_n_reconstruct(path)\n\n        plt.subplot(1,2,1)\n        plt.imshow(rt)\n        plt.title('rich texture - AI generated image')\n        plt.subplot(1,2,2)\n        plt.imshow(pt)\n        plt.title('poor texture - AI generated')\n        plt.show()\n        \n        rt = apply_all_filters(rt)\n        pt = apply_all_filters(pt)\n        plt.subplot(1,2,1)\n        plt.imshow(rt, cmap = 'gray')\n        plt.title('rich texture - AI generated image')\n        plt.subplot(1,2,2)\n        plt.imshow(pt, cmap = 'gray')\n        plt.title('poor texture - AI generated')\n        plt.show()\n\n        rt, pt = smash_n_reconstruct(path)\n        \n        # Apply filters and ensure consistent shape\n        frt = tf.cast(tf.expand_dims(apply_all_filters(rt), axis=-1), dtype=tf.float64)\n        fpt = tf.cast(tf.expand_dims(apply_all_filters(pt), axis=-1), dtype=tf.float64)\n        \n        # Ensure shape\n        frt = tf.ensure_shape(frt, [256, 256, 1])\n        fpt = tf.ensure_shape(fpt, [256, 256, 1])\n        \n        # Add batch dimension, so shape becomes [1, 256, 256, 1]\n        frt = tf.expand_dims(frt, axis=0)\n        fpt = tf.expand_dims(fpt, axis=0)\n        \n        return frt, fpt\n        \n    except Exception as e:\n        print(f\"Error processing {path}: {e}\")\n        # Return dummy tensors to avoid breaking the pipeline\n        dummy = tf.zeros([256, 256, 1], dtype=tf.float32)\n        return dummy, dummy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:04:14.273285Z","iopub.status.idle":"2024-12-12T14:04:14.273733Z","shell.execute_reply.started":"2024-12-12T14:04:14.273482Z","shell.execute_reply":"2024-12-12T14:04:14.273504Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import load_model\nimport numpy as np\nimport cv2 \nimport keras\n# or other image loading libraries\n\n\n# Register the custom layer with Keras\nkeras.utils.get_custom_objects()['featureExtractionLayer'] = featureExtractionLayer\n\n# Load the trained model from the .h5 file\nmodel = load_model('/kaggle/working/classifier_universal.keras')\n\n# Example test data\ntest_image_path = '/kaggle/input/real-fake-image-full-dataset/0_real/1017.png'\n\n# Display image\nimage = cv2.imread(test_image_path)\nplt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\nplt.show()\n\n# preprocess image\ntest_frt, test_fpt = preprocess_image(test_image_path)\n\n# Make a prediction\npredictions = model.predict([test_frt, test_fpt])\nprint(predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T14:04:14.275480Z","iopub.status.idle":"2024-12-12T14:04:14.276034Z","shell.execute_reply.started":"2024-12-12T14:04:14.275786Z","shell.execute_reply":"2024-12-12T14:04:14.275811Z"}},"outputs":[],"execution_count":null}]}